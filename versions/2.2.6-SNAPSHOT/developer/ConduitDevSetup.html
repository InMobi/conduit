<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- Generated by Apache Maven Doxia Site Renderer 1.4 at 2014-02-14 -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Conduit - Dev setup installation</title>
    <style type="text/css" media="all">
      @import url("../css/maven-base.css");
      @import url("../css/maven-theme.css");
      @import url("../css/site.css");
    </style>
    <link rel="stylesheet" href="../css/print.css" type="text/css" media="print" />
    <meta name="Date-Revision-yyyymmdd" content="20140214" />
    <meta http-equiv="Content-Language" content="en" />
        
        </head>
  <body class="composite">
    <div id="banner">
                    <div id="bannerLeft">
                Conduit
                </div>
                    <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                    
                <div class="xleft">
        <span id="publishDate">Last Published: 2014-02-14</span>
                  &nbsp;| <span id="projectVersion">Version: 2.2.6-SNAPSHOT</span>
                      </div>
            <div class="xright">                    <a href=".././" title="Conduit">Conduit</a>
              
                    
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                    
                                          <h5>Modules</h5>
                  <ul>
                  <li class="none">
                          <a href="../conduit-core/index.html" title="Conduit Core">Conduit Core</a>
            </li>
                  <li class="none">
                          <a href="../conduit-distcp/index.html" title="Conduit Distcp">Conduit Distcp</a>
            </li>
                  <li class="none">
                          <a href="../conduit-worker/index.html" title="Conduit Worker">Conduit Worker</a>
            </li>
                  <li class="none">
                          <a href="../conduit-dist/index.html" title="Conduit Distribution">Conduit Distribution</a>
            </li>
                  <li class="none">
                          <a href="../conduit-audit/index.html" title="Conduit Audit">Conduit Audit</a>
            </li>
                  <li class="none">
                          <a href="../conduit-visualization/index.html" title="Conduit Visualization">Conduit Visualization</a>
            </li>
          </ul>
                       <h5>Project Documentation</h5>
                  <ul>
                                                                                                                                                                                <li class="collapsed">
                          <a href="../project-info.html" title="Project Information">Project Information</a>
                  </li>
                                                                    <li class="collapsed">
                          <a href="../project-reports.html" title="Project Reports">Project Reports</a>
                  </li>
          </ul>
                             <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
        <img class="poweredBy" alt="Built by Maven" src="../images/logos/maven-feather.png" />
      </a>
                   
                    
            </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <div class="section">
<h2>Dev setup installation<a name="Dev_setup_installation"></a></h2></div>
<div class="section">
<h4>Hadoop Setup<a name="Hadoop_Setup"></a></h4>
<p>Hadoop on Conduitdev1 and Conduitdev2 was setup using the instructions found in Cloudera <a class="externalLink" href="https://ccp.cloudera.com/display/CDHDOC/CDH3+Deployment+on+a+Cluster">Document</a>.</p>
<p>Both dev1 and dev2 machines have</p>
<p>1. <a href="./NameNode.html">NameNode</a> Directory is found at /etc/hadoop/hdfs/namenode</p>
<p>2. <a href="./DataNode.html">DataNode</a> Directory is found at /etc/hadoop/hdfs/datanode</p>
<p>3. Configuration is found at /etc/hadoop/conf</p>
<p>dev2 machines can run multiple datanodes</p>
<p>1. <a href="./DataNode.html">DataNode</a>2 and Datanode3 Directories are at /etc/hadoop/hdfs/datanode2 and /etc/hadoop/hdfs/datanode3 respectively.</p>
<p>2. Configurations are found at /etc/hadoop/conf2 and /etc/hadoop/conf3 respectively.</p>
<p><a href="./JobTracker.html">JobTracker</a> can be started using &quot;<strong><em>sudo service hadoop-0.20-jobtracker start</em></strong>&quot;</p>
<p><a href="./TaskTracker.html">TaskTracker</a> can be started using &quot;<strong><em>sudo service hadoop-0.20-tasktracker start</em></strong>&quot;</p>
<p><a href="./NameNode.html">NameNode</a> can be started using &quot;<strong><em>sudo service hadoop-0.20-namenode start</em></strong>&quot;</p>
<p><a href="./DataNodes.html">DataNodes</a> can be started using &quot;<em><strong>sudo service hadoop-0.20-datanode start</strong></em>&quot; and services for other 2 are hadoop-0.20-datanode2 and hadoop-0.20-datanode3</p></div>
<div class="section">
<h4>Scribe setup<a name="Scribe_setup"></a></h4>
<p>Scribe is setup using apt repository apt-get install scribe-service-hdfs-orig package. This installs the scribe binary in location /usr/bin.</p>
<p>1. We have a wrapper script which sets the hadoop library class path present in /usr/bin/scribe.sh which should be run in background</p>
<p>2. Logs everything to /tmp/scribe.log.</p>
<p>3. The configuration is present in /etc/scribe.conf.</p>
<p>4. We also have scribe_ctrl.py script present in /usr/bin for stopping, status, reloading etc. for controlling scribe.</p>
<p>NOTE : PLEASE START SCRIBE AS &quot;conduit&quot; USER</p></div>
<div class="section">
<h4>Zookeeper setup<a name="Zookeeper_setup"></a></h4>
<p>Zookeeper is setup using the Cloudera <a class="externalLink" href="https://ccp.cloudera.com/display/CDHDOC/ZooKeeper+Installation">Document</a>. No changes are made from default configuration.</p>
<p>Start &quot;sudo service hadoop-zookeeper-server start&quot;</p>
<p>Stop &quot;sudo service hadoop-zookeeper-server stop&quot;</p></div>
<div class="section">
<h4>Conduit setup<a name="Conduit_setup"></a></h4>
<p>Conduit is setup using the generated deb package using dpkg command. Use the default configuration files present in /etc/conduit/conf to /usr/local/conduit/conf. All the configurations are attached here. Edit for any changes. Remove Symlink /usr/local/conduit and symlink to new /usr/local/conduit-newversion. Starting conduit using the following command</p>
<p>cd /var/log/conduit</p>
<p>. /usr/local/conduit/bin/conduit.sh start /usr/local/conduit/conf/conduit.cfg</p>
<p>For Stopping</p>
<p>/usr/local/conduit/bin/conduit.sh stop /usr/local/conduit/conf/conduit.cfg</p>
<p>Logs are written to the cwd where conduit is started in the above case /var/log/conduit</p>
<p>NOTE : PLEASE START CONDUIT AS &quot;conduit&quot; USER</p></div>
<div class="section">
<h4>Exception Cron Job<a name="Exception_Cron_Job"></a></h4>
<p>We have an entry in /etc/crontab which runs every 15 mins grepping /var/log/conduit/conduit.log for any exceptions. The script is written in python and can be found in /etc/sendmail.py(Attached here in twiki)</p>
<p>1. greps for any exception in logs if found gets the stacktrace from next few statements, caches all the necessary lines</p>
<p>2. checkpoints the file so that same exceptions are not sent again.</p>
<p>3. constructs email using email library in python and adds the caches lines and attaches conduit.log to the email to platform-engg@</p></div>
<div class="section">
<h4>Changing open file handle count<a name="Changing_open_file_handle_count"></a></h4>
<p>To change the open file handle count to 10240, do the following</p>
<p></p>
<ol style="list-style-type: upper-roman">
<li>Add the following in /etc/security/limits.conf :
<ol style="list-style-type: lower-alpha">
<li>hdfs hard nofile 10240</li>
<li>hadoop hard nofile 10240</li>
<li>mapred hard nofile 10240</li>
<li>hadoop soft nofile 10240</li>
<li>hdfs soft nofile 10240</li>
<li>mapred soft nofile 10240</li></ol></li>
<li>Add the following to /etc/pam.d/common-session :
<ol style="list-style-type: lower-alpha">
<li>session required pam_limits.so</li></ol></li>
<li>Logout and login back for the changes to get reflected.</li>
<li>Restart the daemons for the change to effect on them</li>
<li>Verify the limits by looking /proc/&lt;pid&gt;/limits</li></ol></div>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
              Copyright &#169;                    2014
                        <a href="https://github.com/InMobi">InMobi</a>.
            All Rights Reserved.      
                    
                  </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
